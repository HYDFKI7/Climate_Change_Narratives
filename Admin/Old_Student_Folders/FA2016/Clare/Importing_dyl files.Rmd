---
title: "Importing and Processing dyl"
author: "Marc Los Huertos"
date: "12/6/2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyr)
library(dplyr)
library(stringr)
library(reshape2)
source("summarySE.R")
```
# R Resources for Climate Data

## Tutorials and Libraries

Numerous resources are available that might help us (beside this document!) access and process weather data. 

Here is a preliminary list: 

* [R Blogger to Access, Clean, and Plot NOAA tempeature data](http://www.r-bloggers.com/accessing-cleaning-and-plotting-noaa-temperature-data/)
* If you find more resources, please let me know.

# Accessing the Data

## What sites are available for downloading the data?

* [NCDC--NOAA Datasets](https://www.ncdc.noaa.gov/cdo-web/datasets)

For this project, the Global Historical Climate Network may be the most useful data, which can be downloaded from the following an [ftp site](ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/), where I downloaded the entire dataset for the class!

I have loaded these into a class server, but can't see to give you access to it at this point (Nov. 29th). 

# Stations in NOAA Database

The first thing we need to do is to identify locations that we want to evaluate. 

# Download Weather Data

## Identify URLs for data source

Once finding data sources, you might find URLs with ftp or http protocols -- it shouldn't matter which type you find. 

For example, using the NOAA's website, I found the following URL, [ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/](ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/), to download data from the Global Historical Climatalogical Network (GHCDN), where an entire dataset can be downloaded. 

Alternatively, another [NCDC-NOAA Directory](ftp://ftp.ncdc.noaa.gov/pub/data/noaa/) seems to have data by year. But please look at the [readme.txt](ftp://ftp.ncdc.noaa.gov/pub/data/noaa/readme.txt) that describes the data and let me know and I will make a note of what it contains.

## GHCND Data

One major source of data is the GHCND. I downloaded the file to my computer, then uploaded some example data into the R project Data directory.

# Reading Data into R

## What is the data format?

Before reading data, we need to determine the file structure. For example, dly data files have the following format, where headers are lost and each column is separated by tabs that are lost in text rendions. Thus, we'll need a key to intepret the data.

Thankfully, there is a [readme.tex file](ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt) that provides a key to the file structure. I suggest you read it carefully and to understand what is in the database.

## File Structure Keys

Although these keys are a bit daunting to read at first, we will appreciate the consistancy soon! Below is the structure of dly files, which is cut off, so be sure the check out the readme.txt file for a complete list: 

| Parameter   | Columns | Variable Type |
|-------------|---------|---------------|
|ID           | 1-11    | Character     |
|YEAR         | 12-15   |Integer |
|MONTH        |16-17    |Integer |
|ELEMENT      |18-21    |Character |
|VALUE1       |22-26    |Integer |
|MFLAG1       |27-27    |Character |
|QFLAG1       |28-28  | Character|
|SFLAG1       |29-29 |  Character|
|VALUE2       |30-34  | Integer|
|MFLAG2       |35-35 |  Character|
|QFLAG2       |36-36  | Character|
|SFLAG2       |37-37 |  Character|
|  .          | .         | .|
|  .          | .        |  .|
|  .          | .       |   .|
|VALUE31    |262-266   |Integer|
|MFLAG31    |267-267   |Character|
|QFLAG31    |268-268   |Character|
|SFLAG31    |269-269   |Character|


# Processing Data

Since the data have a re-occuring set of variable names, I decided to create a vector of variable names, many of which are nearly the same. So, as you'll see, I had to create a loop to avoid having to type a ton (or 31 :-)) of different variables.

```{r newvariables}
# Create New Varible Names
MFLAG=NA; QFLAG=NA; SFLAG=NA; VALUE=NA
for (i in 1:31){
VALUE[i] = paste("DATE", i, sep="")
MFLAG[i] = paste("MFLAG", i, sep="")
QFLAG[i] = paste("QFLAG", i, sep="")
SFLAG[i] = paste("SFLAG", i, sep="")
}

# Vector of variable names converted from a transposed matrix
tmp = as.vector(t(matrix(data=c(VALUE, MFLAG, QFLAG, SFLAG), ncol=4)))
Names = c("ID", "YEAR", "MONTH", "ELEMENT", tmp); length(Names)
```

# Process Selected Data Files

## Reading .dly file into R

Now that we have a good idea of what these files look like, I have created a loop to read the files and select the rows where the maximum temperature was recorded ("TMAX").

USE Internet Explorer

ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/all/

file.choose()

```{r}
file = "/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/Wendy/USW00013874.dly"
file = "/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/Clare/USW00013777.dly"

dly <- read.fwf(file, widths = c(11, 4, 2, 4, rep(c(5, 1, 1, 1),31)))
names(dly) <- Names; str(dly)

```

Once the file has been read, then I modified the file to make it useful, where I needed to re-arrange the file so we don't have a days of the month across the top, but as rows. 

Using a library reshape2, where the melt command converts all unlisted columns into a new column called 'variable'. 

```{r melt, warning=F}
tmp1 = melt(dly, id=c("ID", "YEAR", "MONTH", "ELEMENT")); head(tmp1)
```

Now, we are going to select just TMAX
```{r}
tmp1 = subset(tmp1, ELEMENT=="TMAX", select=c(ID, YEAR, MONTH, variable, ELEMENT, value))
head(tmp1)
```

Converting the variable (DATE1...DATE31) to numeric values
```{r}
unique(tmp1$variable)
tmp1$end = nchar(as.character(tmp1$variable))
tmp1$regexpr = as.vector(regexpr('DATE', as.character(tmp1$variable))); head(tmp1)
tmp2 <- subset(tmp1, tmp1$regexpr > 0); tmp2$start=tmp2$regexpr + 4; head(tmp2)
tmp2$DAY = as.numeric(str_sub(tmp2$variable,tmp2$start,tmp2$end)); head(tmp2); unique(tmp2$DAY)
tmp2$value = as.numeric(tmp2$value)
tmp2$value[tmp2$value==-9999] = NA; head(tmp2)
tmp2$TMAX = tmp2$value/10

drops <- c("variable","value", "nchar", "regexpr", "end", "start")
tmp2 <-tmp2[ , !(names(tmp2) %in% drops)]
head(tmp2)
# Sort by vector name [z] then [x]
TMAX <- tmp2[with(tmp2, order(YEAR, MONTH, DAY)),]

head(TMAX)

TMAX$DECADE = round(TMAX$YEAR, -1)
# names(tmp1)
```

Now the data is ready to be visualized!

# Presenting the Results

## Summarizing the Results

plot(TMAX ~ YEAR, TMAX[TMAX$ELEMENT=="TMAX",])


monthlymeans <- aggregate(TMAX ~ YEAR + MONTH, data=TMAX[TMAX$ELEMENT=="TMAX",], mean)

head(monthlymeans)
monthlymeans$YM <- monthlymeans$YEAR + (monthlymeans$MONTH - 1)/12

plot(TMAX ~ YM, data=monthlymeans)

monthly.lm <- lm(TMAX ~ YM, data=monthlymeans)
summary(monthly.lm)

abline(coef(monthly.lm), col="blue")

plot(TMAX ~ YM, data=monthlymeans, ty='l')

jan.lm <- lm(TMAX ~ YM, data=monthlymeans[monthlymeans$MONTH==7,])
summary(jan.lm)

abline(coef(jan.lm), col="blue")

plot(TMAX ~ YM, data=monthlymeans, ylab ="Max Temp", xlab="Year", main="Max Temp by Year")

abline(coef(monthly.lm), col="blue")

for July
plot(TMAX ~ YM, data=monthlymeans[monthlymeans$MONTH==7,], ylab ="Max Temp", xlab="Year", main="Max Temp in July by Year")
abline(coef(jan.lm), col="blue")
